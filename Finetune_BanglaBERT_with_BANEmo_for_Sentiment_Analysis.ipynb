{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "t9SYXDlBmd-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I recently published the BANEmo dataset in my IEEE paper [*(link)*](https://ieeexplore.ieee.org/document/11171926), which contains Bangla comments annotated with emotion labels. To demonstrate its practical use, we are goint to fine‚Äëtune the *BanglaBERT* transformer based model for bangla sentiment classification. Not only that, after building the fine-tuned model, we will publish the model in Hugging Face so that anyone can load the model."
      ],
      "metadata": {
        "id": "wy3tJD49mhDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Bangla dataset contains 15k comments. These comments have been meticuloulsy labelled by multiple annotators. Based on the sentiment of each comment, they were categorized to many labels: *Happiness, Sadness, Disgust, Anger, Fear, Surprise, Sarcasm* etc. The dataset is imbalanced, so we will only keep the sentiment categories *Happiness* and *sadness*."
      ],
      "metadata": {
        "id": "V0iCgAlr5PVB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Necessary Libraries"
      ],
      "metadata": {
        "id": "Vxg0ffWZnQKI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WpAq5atl-vZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_scheduler\n",
        "import torch\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)"
      ],
      "metadata": {
        "id": "6GKaIwqDuRMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bangla_comments=pd.read_csv(filepath_or_buffer=\"/content/drive/MyDrive/Dataset/Bangla Comments.csv\")\n",
        "bangla_comments.head()"
      ],
      "metadata": {
        "id": "w3LfduQ1l_-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the labels annotated by multiple annotators, and we only choose the label as the finaltag which received the most votes from the annotators."
      ],
      "metadata": {
        "id": "AS7_1QzRn9gQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the names of the columns"
      ],
      "metadata": {
        "id": "SBbIg_iQoSIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bangla_comments.columns"
      ],
      "metadata": {
        "id": "RBRVm0HGl_7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need to clean the name of these columns and keep only the columns those are necessary."
      ],
      "metadata": {
        "id": "oOydrtkmoeHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bangla_comments.columns=bangla_comments.columns.str.strip()\n",
        "bangla_comments.columns"
      ],
      "metadata": {
        "id": "fdGqU41_l_43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bangla_comments01=bangla_comments[['Comments','FinalTag']]\n",
        "bangla_comments01.head()"
      ],
      "metadata": {
        "id": "Z6bghYfal_2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check out the number of comments in each sentiment class"
      ],
      "metadata": {
        "id": "hipvp_DMpWGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bangla_comments01['FinalTag'].value_counts()"
      ],
      "metadata": {
        "id": "05QjJLTEl_zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will keep the sentiment class *Happiness* and *Sadness* for binary classification."
      ],
      "metadata": {
        "id": "ZtNqM72pp0wA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bangla_comments02=bangla_comments01[bangla_comments01['FinalTag'].isin(['Happiness','Sadness'])]"
      ],
      "metadata": {
        "id": "Ws0_3_BJl_wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bangla_comments02['FinalTag'].value_counts()"
      ],
      "metadata": {
        "id": "hbomSGURl_uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new sentiment *labels* column to map happiness to 1 and sadness to 0"
      ],
      "metadata": {
        "id": "3Byy1noBrPM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bangla_comments02=bangla_comments02.copy()\n",
        "bangla_comments02.loc[:,'labels']=bangla_comments02['FinalTag'].map({'Happiness':1, 'Sadness':0})\n",
        "bangla_comments02.head()"
      ],
      "metadata": {
        "id": "ri61A63Dl_rX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reset the index of the dataset."
      ],
      "metadata": {
        "id": "iH7OA-X3Evi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bangla_comments02=bangla_comments02.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "EssX13uQl_og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bangla_comments02.head()"
      ],
      "metadata": {
        "id": "PeoA5Jbvl_l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bangla_comments02['labels'].value_counts()"
      ],
      "metadata": {
        "id": "NHz_DeSVy-6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't need the *FinalTag* column. We can remove this column."
      ],
      "metadata": {
        "id": "eHTmJvbtFm3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bangla_comments02.drop(columns=['FinalTag'], inplace=True)"
      ],
      "metadata": {
        "id": "lpo-iA9bFuI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the Dataset in to Train and Validation Set"
      ],
      "metadata": {
        "id": "b6Fi2NEpFHp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, validation_df=train_test_split(bangla_comments02, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "BV-WuUHPl_jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_df['labels'].value_counts()"
      ],
      "metadata": {
        "id": "zDtAAco73vU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset using Huggingface"
      ],
      "metadata": {
        "id": "dZO8i6qFGg83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to save the train set and the validation set in csv format so that we can load the dataset using the *load_dataset* function from huggingface."
      ],
      "metadata": {
        "id": "8_2onYTOGRrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv('train.csv', index=False)\n",
        "validation_df.to_csv('validation.csv', index=False)"
      ],
      "metadata": {
        "id": "hlRZdQ4_l_g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you‚Äôll have train.csv and valid.csv in our Colab working directory.\n",
        "Once saved, you can load them."
      ],
      "metadata": {
        "id": "WT2blG6_G5EH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "raw_datasets=load_dataset('csv', data_files={'train':'train.csv', 'validation':'validation.csv'})"
      ],
      "metadata": {
        "id": "nWSlIvnrl_eP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets"
      ],
      "metadata": {
        "id": "60QJ7gvSl_bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check out the first comments in the train and validation datasest."
      ],
      "metadata": {
        "id": "sCYmmLc4HcJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_datasets['train']['Comments'][0])"
      ],
      "metadata": {
        "id": "3tPQ-pKel_ZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_datasets['validation']['Comments'][0])"
      ],
      "metadata": {
        "id": "8OpvyAFol_WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Necessary Libraries"
      ],
      "metadata": {
        "id": "tt8nFvcwI8DI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AQNW54f4JEz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate"
      ],
      "metadata": {
        "id": "NrMhUyXfJQwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Transformer Model and Tokenizer"
      ],
      "metadata": {
        "id": "2Pz4Be2QIpLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model='sagorsarker/bangla-bert-base'\n",
        "tokenizer=AutoTokenizer.from_pretrained(transformer_model)"
      ],
      "metadata": {
        "id": "uqbNoJjB3AVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function for Tokenization"
      ],
      "metadata": {
        "id": "GB7rRgc7IHlY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function to tokenize each of the comments from train, and validation dataset."
      ],
      "metadata": {
        "id": "7s6ivV0MIKD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(dataset):\n",
        "  # Ensure all comments are strings to avoid type errors\n",
        "  comments_as_strings = [str(comment) if comment is not None else \"\" for comment in dataset['Comments']]\n",
        "  return tokenizer(comments_as_strings, truncation=True)\n",
        "\n",
        "#Dataset.map will apply the tokenize_function across all the rows of each split in the dataset\n",
        "tokenized_dataset=raw_datasets.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "gF0_gCKrmTvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging Face has Dataset.map() method that tells us how to feed data into our function. *batched=True* makes tokenizer function process multiple sentences at once instead of one by one, which speeds up tokenization and is the recommended way to use Hugging Face tokenizers."
      ],
      "metadata": {
        "id": "KiITUBAdLEH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check out the tokenized dataset. As you can see three new features have been introduced *'input_ids', 'token_type_ids', 'attention_mask'*"
      ],
      "metadata": {
        "id": "9jUB5SS4LO4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "nWkZP7G0mTsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Collator"
      ],
      "metadata": {
        "id": "JThvDoPvLYAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Collator helps to pad the tokenized sentences to the maximum length per batch."
      ],
      "metadata": {
        "id": "ZKGCR3aWLZ7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator=DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "XjGkLpxomTno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data for training"
      ],
      "metadata": {
        "id": "Sg6kVKhPLfGY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before actually writing our training loop, we will need to define a few objects. The first ones are the dataloaders we will use to iterate over batches. But before we can define those dataloaders, we need to apply a bit of postprocessing to our tokenized_datasets, to take care of some things that the Trainer did for us automatically. Specifically, we need to:\n",
        "\n",
        "1. Remove the columns corresponding to values the model does not expect (like the *Comments*).\n",
        "2. We don't need to rename the column *labels* because the model expects the argument to be named *labels*.\n",
        "3. Set the format of the datasets so they return PyTorch tensors instead of lists.\n",
        "4. Also we can remove the column *token_type_ids* as we have only one comment per row. But if you want you can keep it. No harm."
      ],
      "metadata": {
        "id": "le9yryjNLi4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset=tokenized_dataset.remove_columns(['Comments','token_type_ids'])\n",
        "tokenized_dataset.set_format('torch')"
      ],
      "metadata": {
        "id": "h8PWRvkAmTk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset['train'].column_names"
      ],
      "metadata": {
        "id": "73dvEX51mTiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loader"
      ],
      "metadata": {
        "id": "Aj2oT2ToMMSA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loader function will shuffle the train dataset, create batches of examples with padding and feed to the model for training. Instead of feeding one sentence at a time, it groups multiple examples (e.g., 8 if batch_size=8) into a single batch.\n",
        "Batch dictionary: Each batch is a dictionary with keys like:\n",
        "\n",
        "* input_ids ‚Üí tokenized sentence IDs\n",
        "\n",
        "* attention_mask ‚Üí indicates which tokens are real vs padding\n",
        "\n",
        "* token_type_ids (for sentence pairs, not needed for our bangla dataset)\n",
        "\n",
        "* labels ‚Üí sentiment labels (0 or 1)"
      ],
      "metadata": {
        "id": "3EEugViAMNiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader=DataLoader(dataset=tokenized_dataset['train'], shuffle=True, batch_size=8, collate_fn=data_collator)\n",
        "evaluation_dataloader=DataLoader(dataset=tokenized_dataset['validation'], shuffle=True, batch_size=8, collate_fn=data_collator)"
      ],
      "metadata": {
        "id": "P9VyVu04mUgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a look at the first batch from the dataloader for train dataset"
      ],
      "metadata": {
        "id": "62IydsmTNB15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader:\n",
        "  break\n",
        "{k: v.shape for k,v in batch.items()}"
      ],
      "metadata": {
        "id": "pKdO4Cc_mUdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Model"
      ],
      "metadata": {
        "id": "3embhFICNVJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we‚Äôre completely finished with data preprocessing, let‚Äôs turn to the model. We instantiate it exactly as we did it before."
      ],
      "metadata": {
        "id": "pEE7htmMNXmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=AutoModelForSequenceClassification.from_pretrained(transformer_model, num_labels=2)"
      ],
      "metadata": {
        "id": "rC1M8GOYmUa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make sure that everything will go smoothly during training, we pass our first batch of training data to this model. The first batch contains 8 sentences and the model will return 2 logits for each sentence, one for negative and another for positive sentiment."
      ],
      "metadata": {
        "id": "rJwmBGwYNwpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs=model(**batch)\n",
        "print(outputs)"
      ],
      "metadata": {
        "id": "toBJYrg_mUYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will want to use the GPU if we have access to one. To do this, we define a device we will put our model and our batches on."
      ],
      "metadata": {
        "id": "1c6kx4XUOidx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "device"
      ],
      "metadata": {
        "id": "B-uqMH9cNYkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "Iys8kpLBOB-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We‚Äôre just missing two things: an *optimizer* and a *learning rate scheduler*. Since we are trying to replicate what the Trainer was doing by hand, we will use the same defaults. The optimizer used by the Trainer is *AdamW*, which is the same as *Adam*, but with a twist for *weight decay regularization*."
      ],
      "metadata": {
        "id": "joNdBd4BOFOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=AdamW(model.parameters(),lr=0.00005)"
      ],
      "metadata": {
        "id": "J4NdKjApmUVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Scheduler"
      ],
      "metadata": {
        "id": "8gNfEIoCOJVx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, the learning rate scheduler used by default is just a linear decay from the maximum value 0.00005 to 0. To properly define it, we need to know the number of training steps we will take, which is the number of epochs we want to run multiplied by the number of training batches (which is the length of our training dataloader). The Trainer uses three epochs by default, so we will follow that."
      ],
      "metadata": {
        "id": "VmCBwU0TOL8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler"
      ],
      "metadata": {
        "id": "iozVVjmRmUSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=3\n",
        "num_training_steps=num_epochs*len(train_dataloader)\n",
        "print(num_training_steps)"
      ],
      "metadata": {
        "id": "uHltnJ5UNYrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_scheduler=get_scheduler('linear', optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
      ],
      "metadata": {
        "id": "u4mZjhxTNYnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "kas26ropOf-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now ready to train! To get some sense of when training will be finished, we add a progress bar over our number of training steps, using the tqdm library. Caution: the training will take a while."
      ],
      "metadata": {
        "id": "rD4-06TnPagJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "progress_bar=tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "  for batch in train_dataloader:\n",
        "    batch={k: v.to(device) for k,v in batch.items()}\n",
        "    outputs=model(**batch)\n",
        "    loss=outputs.loss\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    learning_scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "    progress_bar.update(1)"
      ],
      "metadata": {
        "id": "P4K3mc2TNYho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "W2jTVTESPpbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After we train our transformer model on the train dataset, we need to evaluate the performance of our model on the validation set."
      ],
      "metadata": {
        "id": "qw5rwgxwPsaF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use a metric provided by the *Evaluate* library. Metrics can actually accumulate batches for us as we go over the prediction loop with the method *add_batch()*. Once we have accumulated all the batches, we can get the final result with *metric.compute()*. Here‚Äôs how to implement all of this in an evaluation loop."
      ],
      "metadata": {
        "id": "sGzNQaInPw0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy=evaluate.load('accuracy')\n",
        "f1_score=evaluate.load('f1')\n",
        "\n",
        "model.eval()\n",
        "for batch in evaluation_dataloader:\n",
        "  batch={k: v.to(device) for k,v in batch.items()}\n",
        "  with torch.no_grad():\n",
        "    outputs=model(**batch)\n",
        "\n",
        "  predictions=torch.argmax(outputs.logits, dim=-1)\n",
        "  accuracy.add_batch(predictions=predictions, references=batch['labels'])\n",
        "  f1_score.add_batch(predictions=predictions, references=batch['labels'])"
      ],
      "metadata": {
        "id": "mhdGllQbN9ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy: {accuracy.compute()}')\n",
        "print(f'F-1 Score: {f1_score.compute()}')"
      ],
      "metadata": {
        "id": "UMEuSOMLOjT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the Model"
      ],
      "metadata": {
        "id": "Zbo5M4V6ld70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"bangla_sentiment_model\")\n",
        "tokenizer.save_pretrained(\"bangla_sentiment_model\")"
      ],
      "metadata": {
        "id": "GtMu5TcYlwcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both the model and tokenizer will be saved into a folder named *bangla_sentiment_model*.\n",
        "\n",
        "That folder is created in your current working directory (where our Python script or notebook is running).\n",
        "\n",
        "Inside it, we will find files like:\n",
        "\n",
        "* config.json ‚Üí model configuration\n",
        "\n",
        "* pytorch_model.bin ‚Üí model weights\n",
        "\n",
        "* tokenizer.json / vocab.txt ‚Üí tokenizer vocabulary\n",
        "\n",
        "* special_tokens_map.json ‚Üí tokenizer special tokens"
      ],
      "metadata": {
        "id": "nMs52rQnltpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check the location"
      ],
      "metadata": {
        "id": "xTONcNpan14m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will show you all the files saved."
      ],
      "metadata": {
        "id": "XCkeYHYioVIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(\"bangla_sentiment_model\")"
      ],
      "metadata": {
        "id": "MOhDHilkmQj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the saved model"
      ],
      "metadata": {
        "id": "egjJZCYOoYPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bangla_sentiment_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bangla_sentiment_model\")"
      ],
      "metadata": {
        "id": "h_0tBSUwmQhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the model in Google drive"
      ],
      "metadata": {
        "id": "EKC5-bQf6jsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/bangla_sentiment_model\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/bangla_sentiment_model\")"
      ],
      "metadata": {
        "id": "zPRNeIcX6mKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the model from google drive"
      ],
      "metadata": {
        "id": "wXbHQgJuoXm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/bangla_sentiment_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/bangla_sentiment_model\")"
      ],
      "metadata": {
        "id": "DpcecODEmQfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate again"
      ],
      "metadata": {
        "id": "W0LEtEM08rnM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the loaded model again to check the performance is still the same."
      ],
      "metadata": {
        "id": "K4fwu42B8t1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "device"
      ],
      "metadata": {
        "id": "F4_dGL1S9Hw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "izkfaDu490zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy=evaluate.load('accuracy')\n",
        "f1_score=evaluate.load('f1')\n",
        "\n",
        "model.eval()\n",
        "for batch in evaluation_dataloader:\n",
        "  batch={k: v.to(device) for k,v in batch.items()}\n",
        "  with torch.no_grad():\n",
        "    outputs=model(**batch)\n",
        "\n",
        "  predictions=torch.argmax(outputs.logits, dim=-1)\n",
        "  accuracy.add_batch(predictions=predictions, references=batch['labels'])\n",
        "  f1_score.add_batch(predictions=predictions, references=batch['labels'])"
      ],
      "metadata": {
        "id": "kvQJyrohmQcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Accuracy"
      ],
      "metadata": {
        "id": "YJFoMBcy9dgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy: {accuracy.compute()}')\n",
        "print(f'F-1 Score: {f1_score.compute()}')"
      ],
      "metadata": {
        "id": "IQfjyHMFmQaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our fine-tuned bangla bert model gained an accuracy of 84% which is pretty good."
      ],
      "metadata": {
        "id": "IHBRbF--9OPc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tIdGY93KmQXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aq6bQx_pmQU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Publish the Model to Hugging Face"
      ],
      "metadata": {
        "id": "nRAdZSqPjnPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will log in to hugging face and push our model the hugging face space. We will need to create a repository on hugging face hub where we will push and save our model."
      ],
      "metadata": {
        "id": "pH85Bk3RkbvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Hugging Face tools"
      ],
      "metadata": {
        "id": "UuNqpZnSdJ5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gNcxXoIQdNHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Log in to Hugging Face"
      ],
      "metadata": {
        "id": "n-atyootlBYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "HZgwNgbTdZXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Model Repository"
      ],
      "metadata": {
        "id": "HEBQlCeVdlMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can either:\n",
        "\n",
        "* Create a new repo manually at huggingface.co/new, or\n",
        "\n",
        "* Do it programmatically:"
      ],
      "metadata": {
        "id": "XkS_ZZNFdqW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "api.create_repo(repo_id=\"bangla-sentiment-banglabert\", private=False)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5kMh41PAdp8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload the Saved Model"
      ],
      "metadata": {
        "id": "qhm1oXvUetgo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we saved our model in Google Drive (/content/drive/MyDrive/bangla_sentiment_model), we can upload that folder:"
      ],
      "metadata": {
        "id": "OAC2WTASeyVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api = HfApi()\n",
        "\n",
        "api.upload_folder(\n",
        "    folder_path=\"/content/drive/MyDrive/bangla_sentiment_model\",\n",
        "    repo_id=\"sakhawat-hossen/bangla-sentiment-banglabert\"\n",
        ")"
      ],
      "metadata": {
        "id": "G0_ydc27OjRp",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reload From Hub"
      ],
      "metadata": {
        "id": "fjPN9unQfbya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once our model for bangla sentiment analysis is uploaded in hugging face hub, anyone can load it directly:"
      ],
      "metadata": {
        "id": "BJRG-29rfeco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"sakhawat-hossen/bangla-sentiment-banglabert\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sakhawat-hossen/bangla-sentiment-banglabert\")"
      ],
      "metadata": {
        "id": "uRFmS4pUOjPF",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check the model output"
      ],
      "metadata": {
        "id": "xzQmDpRmheuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "text = \"‡¶Ü‡¶ú ‡¶Ü‡¶Æ‡¶ø ‡¶ñ‡ßÅ‡¶¨ ‡¶ñ‡ßÅ‡¶∂‡¶ø‡•§\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
        "\n",
        "print(\"Prediction:\", \"Happiness üòÄ\" if prediction == 1 else \"Sadness üò¢\")"
      ],
      "metadata": {
        "id": "mdP8K3aNOjMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "We3Gm5OJOjJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tGVcPNgrhOob"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}